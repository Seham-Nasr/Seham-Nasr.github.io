---
title: "End-to-End Speech Recognition For Arabic Dialects"
collection: publications
category: manuscripts
permalink: /publication/E2Espeech
#excerpt: 'This paper is about Arabic Speech processing'
# date: 2024-12-01
venue: 'Arabian Journal for Science and Engineering'
paperurl: 'https://link.springer.com/article/10.1007/s13369-023-07670-7'
#citation: 'Seham, Nasr. (2024)."E2E" <i>Springer</i>'
---
Authors: S. Nasr, R. Duwairi, M. Quwaider

# Abstract
Automatic speech recognition or speech-to-text is a human-machine interaction task, and although it is challenging, it is attracting several researchers and companies such as Google, Amazon, and Facebook. End-to-end speech recognition is still in its infancy for low-resource languages such as Arabic and its dialects due to the lack of transcribed corpora. In this paper, we have introduced novel transcribed corpora for Yamani Arabic, Jordanian Arabic, and multi-dialectal Arabic. We also designed several baseline sequence-to-sequence deep neural models for Arabic dialects’ end-to-end speech recognition. Moreover, Mozilla’s DeepSpeech2 model was trained from scratch using our corpora. The Bidirectional Long Short-Term Memory (Bi-LSTM) with attention model achieved encouraging results on the Yamani speech corpus with a 59% Word Error Rate (WER) and 51% Character Error Rate (CER). The Bi-LSTM with attention achieved, on the Jordanian speech corpus, 83% WER and 70% CER. By comparison, the model achieved, on the multi-dialectal Yem-Jod-Arab speech corpus, 53% WER and 39% CER. The performance of the DeepSpeech2 model has superseded the performance of the baseline models with 31% WER and 24% CER for the Yamani corpus; 68 WER and 40 CER for the Jordanian corpus. Lastly, DeepSpeech2 gave better results, on multi-dialectal Arabic corpus, with 30% WER and 20% CER.
